{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e2690b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter url of a medium article: https://medium.com/@sushant.waghmode/successfully-unsuccessful-c8dd9ca7a392\n",
      "paragraphs text = \n",
      " [<p class=\"be b fo fp bj\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar fq\" data-testid=\"authorName\" href=\"/@sushant.waghmode\" rel=\"noopener follow\">Dr Sushant</a></p>, <p class=\"be b fo fp ft\"><span><a class=\"fu fv ah ai aj ak al am an ao ap aq ar fw fx fy\" href=\"/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F24602dc03808&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40sushant.waghmode%2Fsuccessfully-unsuccessful-c8dd9ca7a392&amp;user=Dr+Sushant&amp;userId=24602dc03808\" rel=\"noopener follow\">Follow</a></span></p>, <p class=\"be b ij z ft\"><span class=\"ht\">--</span></p>, <p class=\"be b bf z ft\">Listen</p>, <p class=\"be b bf z ft\">Share</p>, <p class=\"pw-post-body-paragraph kd ke kf kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb jj bj\" id=\"2398\"><em class=\"lc\">Successfully unsuccessful is what they call me.</em></p>, <p class=\"pw-post-body-paragraph kd ke kf kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb jj bj\" id=\"fcf2\"><em class=\"lc\">And I guess I finally get it why. It’s not that I haven’t emasculated my own consciousness by engaging myself into each and every particulate that came along. The amount of energy I have invested in trying to learn things only out of the expectation that one of them would be my golden ticket out of this mediocre life span. I have been consistent, disciplined, passionate and patient. I have tried to cultivate every attribute relevant or irrelevant so that one day all the pieces would come together to make a beautiful masterpiece.</em></p>, <p class=\"pw-post-body-paragraph kd ke kf kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb jj bj\" id=\"6ce4\"><em class=\"lc\">But I was successfully unsuccessful.</em></p>, <p class=\"pw-post-body-paragraph kd ke kf kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb jj bj\" id=\"2911\"><em class=\"lc\">Does that mean I give up? Is this the end? Have I really run out of rope to hold on to? Is this the demise of a soul that tried but never could be? Have the clutches of destiny finally strangled all hope that was left. In the end this material world has prevailed and concurred upon the actions of my soul. Even after all that effort the bottomless pit of failure is where I find myself. Falling endlessly into the void. Torn apart into fragments by the gravitational pull of my failures. But I tried so hard is this really the end. Is this how this story ends?</em></p>, <p class=\"pw-post-body-paragraph kd ke kf kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb jj bj\" id=\"3f2d\"><em class=\"lc\">Nay I say. Never!!</em></p>, <p class=\"pw-post-body-paragraph kd ke kf kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb jj bj\" id=\"c487\"><em class=\"lc\">Until there is a fragment. Until there is a molecule, an atom of my existence, I will return. Each fragment will spontaneously combust like a self-illuminating star and purge upon the darkness. This holy war upon the inevitable will last for eternities to come. For the truth is that I will never give up. Rise from the ashes I will. The winds will howl by my name and I will stare into that bottomless pit and shout into the abyss. You shall not have me! Not now, not today, not tomorrow, not in any time frame. I will fail an infinite times until I chip at your fortress block by block. And in that moment when you presume that I am done I will rise high like a supernova and make my mark upon this world.</em></p>, <p class=\"pw-post-body-paragraph kd ke kf kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb jj bj\" id=\"d63b\"><em class=\"lc\">Successfully unsuccessful, but not yet done.</em></p>, <p class=\"be b ij z ft\"><span class=\"ht\">--</span></p>, <p class=\"be b ij z ft\"><span class=\"ht\">--</span></p>, <p class=\"be b bf z bj\"><span class=\"jj\">Dentist, Councillor, Fitness enthusiast, Poet</span></p>, <p class=\"be b ij z rk rl rm rn ro rp rq rr bj\">Dr Sushant</p>, <p class=\"be b ij z ft\"><span class=\"ht\">--</span></p>, <p class=\"be b ij z ft\"><span class=\"pw-responses-count tp ip\">1</span></p>, <p class=\"be b ij z rk rl rm rn ro rp rq rr bj\">Dr Sushant</p>, <p class=\"be b ij z ft\"><span class=\"ht\">--</span></p>, <p class=\"be b ij z ft\"><span class=\"pw-responses-count tp ip\">1</span></p>, <p class=\"be b ij z ft\"><span class=\"ht\">--</span></p>, <p class=\"be b ij z ft\"><span class=\"pw-responses-count tp ip\">1</span></p>, <p class=\"be b ij z rk rl rm rn ro rp rq rr bj\">AL Anany</p>, <p class=\"be b ij z ft\"><span class=\"ht\">--</span></p>, <p class=\"be b ij z ft\"><span class=\"pw-responses-count tp ip\">161</span></p>, <p class=\"be b ij z rk rl rm rn ro rp rq rr bj\">Unbecoming</p>, <p class=\"be b ij z ft\"><span class=\"ht\">--</span></p>, <p class=\"be b ij z ft\"><span class=\"pw-responses-count tp ip\">931</span></p>, <p class=\"be b ij z rk rl rm rn ro rp rq rr bj\">Deepa Gaitonde</p>, <p class=\"be b ij z ft\"><span class=\"ht\">--</span></p>, <p class=\"be b ij z ft\"><span class=\"pw-responses-count tp ip\">2</span></p>, <p class=\"be b ij z rk rl rm rn ro rp rq rr bj\">Nick Hilton</p>, <p class=\"be b ij z ft\"><span class=\"ht\">--</span></p>, <p class=\"be b ij z ft\"><span class=\"pw-responses-count tp ip\">133</span></p>, <p class=\"be b ij z rk rl rm rn ro rp rq rr bj\">Victor Timi</p>, <p class=\"be b ij z ft\">in</p>, <p class=\"be b ij z rk rl rm rn ro rp rq rr bj\">Level Up Coding</p>, <p class=\"be b ij z ft\"><span class=\"ht\">--</span></p>, <p class=\"be b ij z ft\"><span class=\"pw-responses-count tp ip\">17</span></p>, <p class=\"be b ij z rk rl rm rn ro rp rq rr bj\">Zulie Rane</p>, <p class=\"be b ij z ft\">in</p>, <p class=\"be b ij z rk rl rm rn ro rp rq rr bj\">The Startup</p>, <p class=\"be b ij z ft\"><span class=\"ht\">--</span></p>, <p class=\"be b ij z ft\"><span class=\"pw-responses-count tp ip\">916</span></p>, <p class=\"be b ij z ft\">Help</p>, <p class=\"be b ij z ft\">Status</p>, <p class=\"be b ij z ft\">Writers</p>, <p class=\"be b ij z ft\">Blog</p>, <p class=\"be b ij z ft\">Careers</p>, <p class=\"be b ij z ft\">Privacy</p>, <p class=\"be b ij z ft\">Terms</p>, <p class=\"be b ij z ft\">About</p>, <p class=\"be b ij z ft\">Text to speech</p>, <p class=\"be b ij z ft\">Teams</p>]\n",
      "successfully-unsuccessful-c8dd9ca7a392\n",
      "File saved in directory scraped_articles/successfully-unsuccessful-c8dd9ca7a392.txt\n"
     ]
    }
   ],
   "source": [
    "# Python script to scrape an article given the url of the article and store the extracted text in a file\n",
    "# Url: https://medium.com/@subashgandyer/papa-what-is-a-neural-network-c5e5cc427c7\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup  # Import BeautifulSoup library\n",
    "\n",
    "# function to get the html source text of the medium article\n",
    "def get_page():\n",
    "    global url\n",
    "\n",
    "    # Ask the user to input \"Enter url of a medium article: \" and collect it in url\n",
    "    url = input(\"Enter url of a medium article: \")\n",
    "\n",
    "    # handling possible error\n",
    "    if not re.match(r'https?://medium.com/', url):\n",
    "        print('Please enter a valid website, or make sure it is a medium article')\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Call get method in requests object, pass url and collect it in res\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "# function to remove all the html tags and replace some with specific strings\n",
    "def clean(text):\n",
    "    rep = {\"<br>\": \"\\n\", \"<br/>\": \"\\n\", \"<li>\":  \"\\n\"}\n",
    "    rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "    pattern = re.compile(\"|\".join(rep.keys()))\n",
    "    text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text)\n",
    "    text = re.sub('\\<(.*?)\\>', '', text)\n",
    "    return text\n",
    "\n",
    "def collect_text(soup):\n",
    "    text = f'url: {url}\\n\\n'\n",
    "    para_text = soup.find_all('p')\n",
    "    print(f\"paragraphs text = \\n {para_text}\")\n",
    "    for para in para_text:\n",
    "        text += f\"{para.text}\\n\\n\"\n",
    "    return text\n",
    "\n",
    "# function to save file in the current directory\n",
    "def save_file(text):\n",
    "    if not os.path.exists('./scraped_articles'):\n",
    "        os.mkdir('./scraped_articles')\n",
    "    name = url.split(\"/\")[-1]\n",
    "    print(name)\n",
    "    fname = f'scraped_articles/{name}.txt'\n",
    "    \n",
    "    # write a file using with\n",
    "    with open(fname, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "\n",
    "    print(f'File saved in directory {fname}')\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    text = collect_text(get_page())\n",
    "    save_file(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f8d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
